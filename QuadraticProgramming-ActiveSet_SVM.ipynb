{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4049ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvxopt\n",
      "  Downloading cvxopt-1.3.0-cp39-cp39-win_amd64.whl (12.7 MB)\n",
      "Installing collected packages: cvxopt\n",
      "Successfully installed cvxopt-1.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d051ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important;} </style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de8cea",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [I - Algorithms for quadratic programming ](#sec1)\n",
    "    * [1. The active set method](#sec1_1)\n",
    "* [II - Application of quadratic programming-SVM ](#sec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0e247",
   "metadata": {},
   "source": [
    "# I - Algorithms for quadratic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a52943",
   "metadata": {},
   "source": [
    "The **quadratic programming(QP)** problems are linearly constrained optimization problems with a quadratic objective function.\n",
    "\n",
    "$$ (QP)\n",
    "\\begin{cases}\n",
    "\\min_{x} f(x) := \\min_{x}(\\frac{1}{2}x^THx + c^Tx)\\\\\n",
    "s.t. g(x): = Ax - b \\geq0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Suppose $Q\\in\\mathbb{R^{n\\times n}}$ is symmetric postive semidefinite, $C\\in\\mathbb{R^n}$, $A\\in\\mathbb{R^{n\\times m}}$, $b\\in\\mathbb{R^{m}}$, with $A = (a_1^T, a_2^T, ... a_n^T), b=(b_1, b_2, ... b_n)$, and the feasible region $\\mathcal{F} := \\{x\\in\\mathbb{R^n}|Ax\\geq b\\}$, which can be further separated into inequality constraints $\\mathcal{I} ,\\;a_i^Tx-b_i\\geq0$ and equality constraints $\\mathcal{E},\\;a_i^Tx - b_i = 0$\n",
    "\n",
    "\n",
    "The **Karush-Kuhn-Tucker(KKT) condition** for the above QP problem is:\n",
    "\n",
    "A point $x^* \\in S $ is a minimiser to problem (QP) $\\Longleftrightarrow$ $\\exists $ with\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(Stationarity)\\quad &\\nabla f(x^*) + \\Sigma_i\\lambda_i\\nabla g(x^*) = Hx^*+c+\\Sigma_i\\lambda^Ta = 0 \\\\\n",
    "(Primal\\;feasibility)\\quad &Inequality \\quad a_i^Tx^*\\geq b_i, i\\in\\mathcal{I}\\\\\n",
    "&Equality\\quad  a_i^Tx^*=0, i\\in\\mathcal{E}\\\\\n",
    "(Dual\\;feasibility) \\quad &\\lambda_i \\geq 0, i \\in \\mathcal{I}\\\\\n",
    "(Complementary\\;slackness) \\quad &\\lambda_i(a^T_ix^*-b_i) = 0, i\\in\\mathcal{I}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ad63c",
   "metadata": {},
   "source": [
    "## I-1 The active set method for solving QP <a class='anchor' id='sec1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25d5b4",
   "metadata": {},
   "source": [
    "**Algorithm(Active set)**\n",
    "\n",
    "- Initialization: Start with a feasible point $x^k$ of problem ($QP$)\n",
    "- Start loop: mark step numerator k=0 and then iterate with k. Solve for the minimizer $\\hat{x^k}$ of problem ($QP^k$)\n",
    "$$\n",
    "(QP^k) \\begin{cases}\n",
    "\\min_{x} \\frac{1}{2}x^THx + c^Tx\\\\\n",
    "s.t. a_i^Tx - b_i = 0, i\\in\\mathcal{\\mathcal{J_{k}}}\n",
    "\\end{cases}\n",
    "$$\n",
    "    - Case 1: $\\hat{x^k} \\in\\mathcal{F}$, solve $\\sum\\limits_{i\\in\\mathcal{J_{k}}}\\lambda_ia_i= -\\nabla f(\\hat{x_k})$\n",
    "        - If all $\\lambda_i \\geq 0$, then minimum is found stop loop\n",
    "        - Otherwise choose $s \\in \\mathcal{J_{k}}$ with $\\lambda_s<0$ for example $\\lambda_s=min{\\lambda_i, j\\in\\mathcal{J_k}}$\n",
    "          Set $\\mathcal{J_{k+1}} = ActiveSet(\\hat{x_k})-\\{s\\}$ (Desactivation step)\n",
    "    - Case 2: $\\hat{x^k} \\notin\\mathcal{F}$, for $d=\\hat{x_k}-\\hat{x_{k-1}}$ we determin a minimal $\\alpha<0$ with $a_{i}^T(x+\\alpha d) >= b_{i}$ and set $\\hat{x_{k+1}} = \\hat{x_k}+\\alpha d$ \n",
    "    and $\\mathcal{J_{k+1}}=ActiveSet(\\hat{x_{k+1}})$ (Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f0733e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps is 1\n",
      "Reach Optimization\n",
      "Optimize x is [1.5 0.5]\n",
      "Active set is [0]\n",
      "lambda_value is [0.5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Active set\n",
    "# min 1/2x.THx+c.Tx\n",
    "# s.t. Ax>=b\n",
    "\n",
    "class Active_set(object):\n",
    "    def __init__(self, H, C, A, b):\n",
    "        \"\"\"\n",
    "        params: H, c, A, b defined as the same in QP problem, epsilon the tolerance to test positive value\n",
    "        \"\"\"\n",
    "        self.H = H\n",
    "        self.c = c\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.epsilon = 1e-6\n",
    "\n",
    "    def initial_set(self):\n",
    "        \"\"\"\n",
    "        Initialize the active constraint set\n",
    "        \"\"\"\n",
    "        # Choose the active contraint by simply taking the first\n",
    "        activae_set_rows = [0]\n",
    "\n",
    "        # Find the x0 that satisfy the first constraint in active set\n",
    "        # Find the first coefficient in the chosen constraint that is not zero, let the element of x be b/coeff \n",
    "        # to satisfy the ax=b and set other element simply to be zero\n",
    "        index = np.where(self.A[0] != 0)[0][0]\n",
    "        value = self.A[0][index]\n",
    "        feasible_x = np.zeros(len(self.A[0]))\n",
    "        feasible_x[index] = self.b[0][0]/float(value)\n",
    "\n",
    "        feasible_x = feasible_x.reshape(-1, 1)\n",
    "        return activae_set_rows, feasible_x\n",
    "\n",
    "    def calculate_delta(self, x):\n",
    "        \"\"\"\n",
    "        Calculate the first order derivative at x\n",
    "        \"\"\"\n",
    "        return np.matmul(self.H, x) + self.c\n",
    "\n",
    "    def find_active_set(self):\n",
    "        activate_set_rows, feasible_x = self.initial_set()\n",
    "        steps = 0\n",
    "        while True:\n",
    "            steps += 1\n",
    "            print(\"steps is {}\".format(steps))\n",
    "\n",
    "            # Calculate the derivative of f at current x, and the current active constraint set\n",
    "            partial_x = self.calculate_delta(feasible_x)\n",
    "            actual_A, actual_b, actual_b1 = find_new_data(self.A, self.b, activate_set_rows)\n",
    "            # Solve for lagrangian for mu x = -delta f(x), with current active constraint\n",
    "            delta = Lagrange(self.H, partial_x, actual_A, actual_b)\n",
    "            solution = delta[0: self.H.shape[1]]\n",
    "            # Case 1\n",
    "            if np.sum(np.abs(solution)) < self.epsilon:\n",
    "                outcome = Lagrange(self.H, self.c, actual_A, actual_b1)\n",
    "                lambda_value = outcome[self.H.shape[1]:].flatten()\n",
    "                min_value = lambda_value.min()\n",
    "                # if all lambda > 0 \n",
    "                if min_value >= 0:\n",
    "                    print(\"Reach Optimization\")\n",
    "                    print(\"Optimize x is {}\".format(feasible_x.flatten()))\n",
    "                    print(\"Active set is {}\".format(activate_set_rows))\n",
    "                    print(\"lambda_value is {}\".format(lambda_value))\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                # Desactivation\n",
    "                else:\n",
    "                    index = np.argmin(lambda_value)\n",
    "                    activate_set_rows.pop(index)\n",
    "                    feasible_x = feasible_x\n",
    "                    print(\"Not Reach Optimization\")\n",
    "                    print(\"Feasible x is {}\".format(feasible_x.flatten()))\n",
    "                    print(\"Active set is {}\".format(activate_set_rows))\n",
    "                    print(\"lambda_value is {}\".format(lambda_value))\n",
    "                    print(\"\\n\")\n",
    "            # Case 2        \n",
    "            else:\n",
    "                in_row, alpha_k = self.calculate_alpha(feasible_x, solution.reshape(-1, 1), activate_set_rows)\n",
    "                if in_row == -1:\n",
    "                    alpha = 1\n",
    "                else:\n",
    "                    alpha = min(1, alpha_k)\n",
    "\n",
    "                feasible_x += alpha * solution\n",
    "                # Activation\n",
    "                if alpha != 1:\n",
    "                    activate_set_rows.append(in_row)\n",
    "                    print(\"Not Reach Optimization\")\n",
    "                    print(\"Feasible x is {}\".format(feasible_x.flatten()))\n",
    "                    print(\"Active set is {}\".format(activate_set_rows))\n",
    "                    print(\"\\n\")\n",
    "                    continue\n",
    "                else:\n",
    "                    outcome = Lagrange(self.H, self.c, actual_A, actual_b1)\n",
    "                    lambda_value = outcome[self.H.shape[1]:].flatten()\n",
    "                    min_value = lambda_value.min()\n",
    "                    if min_value >= 0:\n",
    "                        print(\"Reach Optimization\")\n",
    "                        print(\"Optimize x is {}\".format(feasible_x.flatten()))\n",
    "                        print(\"Active set is {}\".format(activate_set_rows))\n",
    "                        print(\"lambda_value is {}\".format(lambda_value))\n",
    "                        print(\"\\n\")\n",
    "                        break\n",
    "                    else:\n",
    "                        index = np.argmin(lambda_value)\n",
    "                        activate_set_rows.pop(index)\n",
    "                        print(\"Not Reach Optimization\")\n",
    "                        print(\"Feasible x is {}\".format(feasible_x))\n",
    "                        print(\"Active set is {}\".format(activate_set_rows))\n",
    "                        print(\"lambda_value is {}\".format(lambda_value))\n",
    "                        print(\"\\n\")\n",
    "\n",
    "    def calculate_alpha(self, x, d, activate_set_rows):\n",
    "        \"\"\"\n",
    "        Calculate the step size param alpha\n",
    "        \"\"\"\n",
    "        min_alpha = 0\n",
    "        inrow = -1\n",
    "        for i in range(self.A.shape[0]):\n",
    "            if i in activate_set_rows:\n",
    "                continue\n",
    "            else:\n",
    "                b_i = self.b[i][0]\n",
    "                a_i = self.A[i].reshape(-1, 1)\n",
    "                low_number = np.matmul(a_i.T, d)[0][0]\n",
    "                if low_number >= 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    new_alpha = (b_i - np.matmul(a_i.T, x)[0][0])/float(low_number)\n",
    "                    if inrow == -1:\n",
    "                        inrow = i\n",
    "                        min_alpha = new_alpha\n",
    "                    elif new_alpha < min_alpha:\n",
    "                        min_alpha = new_alpha\n",
    "                        inrow = i\n",
    "                    else:\n",
    "                        continue\n",
    "        return inrow, min_alpha\n",
    "\n",
    "\n",
    "def Lagrange(H, c, A, b):\n",
    "    # construct the lagrange matrix and solve it\n",
    "    #   |  H  -A.T  |   |  wx  |   | -c |\n",
    "    #   |           | * |      | = |   |\n",
    "    #   |  A   0   |   |  wl  |   |-b  |\n",
    "    up_layer = np.concatenate((H, -A.T), axis=1)\n",
    "    zero_0 = np.zeros([A.shape[0], A.shape[0]])\n",
    "    low_layer = np.concatenate((-A, zero_0), axis=1)\n",
    "    lagrange_matrix = np.concatenate((up_layer, low_layer), axis=0)\n",
    "\n",
    "    actual_b = np.concatenate((-c, -b), axis=0)\n",
    "    lagrange_matrix_inverse = np.linalg.inv(lagrange_matrix)\n",
    "    return np.matmul(lagrange_matrix_inverse, actual_b)\n",
    "\n",
    "\n",
    "def find_new_data(A, b, activate_set_rows):\n",
    "    # Update active constraint\n",
    "    actual_A = A[activate_set_rows]\n",
    "    actual_b = np.zeros_like(b[activate_set_rows])\n",
    "    return actual_A, actual_b, b[activate_set_rows]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \"\"\"\n",
    "    Example 5 of page 171 from chapter 4.2\n",
    "    \n",
    "    f(x) = x1^2 - x1x2 + x2^2 - 3x1\n",
    "    constraints:\n",
    "    -x1-x2>= -2\n",
    "    x1 >= 0\n",
    "    x2 >= 0\n",
    "    -x1 >= -3/2\n",
    "    \n",
    "    thus we have\n",
    "    H = np.array([ [2.0, -1], [-1, 2.0] ])\n",
    "    c = np.array([ [-3.0], [0.0]]).reshape(-1,1)\n",
    "    A = np.array([ [-1.0, -1.0], [1.0, 0],[0, 1],[-1.0, 0.0]])\n",
    "    b = np.array( [ [-2.0], [0], [0], [-3/2] ] ).reshape(-1,1)\n",
    "    \n",
    "    The optimal is obtained at x = [x1, x2] = [1.5, 0.5]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    H = np.array([ [2.0, -1], [-1, 2.0] ])\n",
    "    c = np.array([ [-3.0], [0.0]]).reshape(-1,1)\n",
    "    A = np.array([ [-1.0, -1.0], [1.0, 0],[0, 1],[-1.0, 0.0]])\n",
    "    b = np.array( [ [-2.0], [0], [0], [-3/2] ] ).reshape(-1,1)\n",
    "\n",
    "    test = Active_set(H, c, A, b)\n",
    "    test.find_active_set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e74bfa",
   "metadata": {},
   "source": [
    "# II - Application: SVM <a class='anchor' id='sec2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d1544",
   "metadata": {},
   "source": [
    "In a simpliest case of Support Vector Machine(SVM) to seperate points $x_i\\in\\mathbb{R}^{n}$ to value $y_i\\in\\{-1, 1\\}$with a hyperplane described by  $<\\omega, x>+\\beta=0$, the condtion can be set as $<\\omega, x_i>+\\beta\\geq1$ if $y_i=1$ and $<\\omega,x_i>+\\beta\\leq-1$ if $y_i=-1$, $i\\in\\{1,...,m\\}$. This classification problem can be described as an optimisation problem by finding the maximum 'margin' distance $2/\\sqrt{<\\omega, \\omega>}$ between the two hyperplances $<\\omega, x>+\\beta=1$ and $<\\omega, x>+\\beta=-1$ then be formulated as\n",
    "\n",
    "If the two classes are linearly separateble:\n",
    "$$\n",
    "(QP-linearly\\;seperatable)=\\begin{cases}\n",
    "\\min\\limits_{\\omega}\\frac{1}{2}<\\omega, \\omega>\\\\\n",
    "y_i(<\\omega, x_i>+\\beta)\\geq1 (i=\\{1,...m\\})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "If the two classes are not linearly separatable, we can introduce a nonnegative penalties $\\xi_{i}$ as \"soft\" margin :\n",
    "$$\n",
    "(QP-no\\;linearly\\;seperatable) = \\begin{cases}\n",
    "\\min\\limits_{\\omega}\\frac{1}{2}<\\omega, \\omega> + C\\sum\\limits_{i=1}^{m}\\xi_{i}\\\\\n",
    "y_i(<\\omega, x_i>+\\beta)\\geq1-\\xi_{i} (i=\\{1,...m\\})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95f4de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.6906e+03 -5.2157e+07  1e+08  5e-01  1e-10\n",
      " 1:  3.7354e+04 -1.5377e+07  3e+07  8e-02  1e-10\n",
      " 2:  7.5108e+04 -4.5746e+06  7e+06  2e-02  8e-11\n",
      " 3:  5.7151e+04 -1.4167e+06  2e+06  4e-03  6e-11\n",
      " 4:  4.3432e+03 -1.5789e+05  2e+05  1e-04  6e-11\n",
      " 5: -3.5501e+03 -3.5288e+04  3e+04  1e-13  5e-11\n",
      " 6: -3.7995e+03 -1.4052e+04  1e+04  2e-13  5e-11\n",
      " 7: -4.2746e+03 -1.0660e+04  6e+03  8e-13  7e-11\n",
      " 8: -4.3824e+03 -7.7619e+03  3e+03  9e-13  6e-11\n",
      " 9: -4.7497e+03 -6.9636e+03  2e+03  2e-13  6e-11\n",
      "10: -4.8098e+03 -6.6127e+03  2e+03  5e-13  7e-11\n",
      "11: -5.2507e+03 -5.5924e+03  3e+02  3e-13  7e-11\n",
      "12: -5.3545e+03 -5.3945e+03  4e+01  8e-13  8e-11\n",
      "13: -5.3602e+03 -5.3820e+03  2e+01  4e-13  8e-11\n",
      "14: -5.3618e+03 -5.3805e+03  2e+01  5e-13  8e-11\n",
      "15: -5.3689e+03 -5.3692e+03  3e-01  5e-15  8e-11\n",
      "16: -5.3690e+03 -5.3690e+03  3e-03  4e-13  9e-11\n",
      "Optimal solution found.\n",
      "Lambdas =  [9.99999998e+02 9.99999894e+02 9.24249058e-04 2.01519414e+02\n",
      " 2.92835862e+02 1.29625475e+01 9.24249212e-04 4.24356526e+01\n",
      " 1.26391845e+02 4.96624508e-04 5.14940025e+02 9.76249570e+01\n",
      " 4.03575552e+02 9.99999906e+02 1.94764936e+02 4.84010365e+02] \n",
      "\n",
      "w =  [-0.50907356  0.77065523 -0.64007985 -1.12351062 -0.11931081 -0.19364615\n",
      " -0.50937195 -0.28859075 -1.07356786] \n",
      "\n",
      "b =  [14.5911218] \n",
      "\n",
      "Precision :  97.87 %\n",
      "Recall :  75.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byhuang\\AppData\\Local\\Temp\\ipykernel_9120\\970288415.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testing_data['Prediction'] = testing_data_X.apply(lambda x: classifier(W,x,beta), axis=1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Read breast-cancer-diagnostic csv files\n",
    "import pandas as pd\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', header=None)\n",
    "\n",
    "# Adjust column names\n",
    "headers = ['ID', 'Clump Thickness+A20', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
    "          'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mistoses', 'Class']\n",
    "data.columns = list(map(lambda x: x.replace(\" \", '_'), headers))\n",
    "\n",
    "# Data cleaning\n",
    "data = data[data['Bare_Nuclei']!=\"?\"].astype(int) # remove missing value lines\n",
    "data = data.drop([\"ID\"], axis=1) # drop ID column\n",
    "data['Class'] = np.where(data['Class']==2,1,-1) # Adjust labels\n",
    "\n",
    "# Split data into training set and testing set\n",
    "training_data = data[:120]\n",
    "training_data_X = training_data.iloc[:,:9]\n",
    "training_data_y = training_data.iloc[:,-1]\n",
    "\n",
    "testing_data = data[120:]\n",
    "testing_data_X = testing_data.iloc[:,:9]\n",
    "testing_data_y = testing_data.iloc[:,-1]\n",
    "\n",
    "# Initialize values and computing the input params\n",
    "X = training_data_X.to_numpy()\n",
    "y = training_data_y.to_numpy()\n",
    "\n",
    "C = 1000\n",
    "m, n = X.shape\n",
    "y = y.reshape(-1,1)*1.\n",
    "X_dash = y*X\n",
    "H = np.dot(X_dash, X_dash.T)*1.\n",
    "\n",
    "# Converting the input into cvxopt format\n",
    "P = cvxopt_matrix(H)\n",
    "q = cvxopt_matrix(-np.ones((m,1)))\n",
    "G = cvxopt_matrix(np.vstack((np.eye(m)*-1, np.eye(m))))\n",
    "h = cvxopt_matrix(np.hstack((np.zeros(m), np.ones(m)*C)))\n",
    "A = cvxopt_matrix(y.reshape(1,-1))\n",
    "b = cvxopt_matrix(np.zeros(1))\n",
    "\n",
    "# Run solver\n",
    "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "lambdas = np.array(sol['x'])\n",
    "\n",
    "# Computing and printing params\n",
    "w = ((y * lambdas).T @ X).reshape(-1,1)\n",
    "S = (lambdas > 1e-4).flatten()\n",
    "b = y[S] - np.dot(X[S], w)\n",
    "\n",
    "# Display results\n",
    "print('Lambdas = ', lambdas[lambdas > 1e-4], \"\\n\")\n",
    "print('w = ', w.flatten(), \"\\n\")\n",
    "print('b = ', b[0], \"\\n\")\n",
    "\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "def classifier(w, x, b):\n",
    "    return np.sign(np.dot(w, x)+b)\n",
    "\n",
    "# Set w and beta\n",
    "W = w.flatten()\n",
    "beta = b[0]\n",
    "\n",
    "\n",
    "# Run classifier\n",
    "testing_data['Prediction'] = testing_data_X.apply(lambda x: classifier(W,x,beta), axis=1).astype(int)\n",
    "\n",
    "# -1 means positive of having cancer, +1 means negative (healty)\n",
    "TP  = testing_data[(testing_data['Class'] == -1) & (testing_data['Prediction'] == -1)].shape[0]\n",
    "TN  = testing_data[(testing_data['Class'] == 1) & (testing_data['Prediction'] == 1)].shape[0]\n",
    "FP = testing_data[(testing_data['Class'] == 1) & (testing_data['Prediction'] == -1)].shape[0]\n",
    "FN = testing_data[(testing_data['Class'] == -1) & (testing_data['Prediction'] == 1)].shape[0]\n",
    "\n",
    "print(\"Precision : \", round(TP/(TP+FP)*100, 2), \"%\")\n",
    "print(\"Recall : \", TP/(TP+FN)*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134240b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
